{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In `main.ipynb` the goodfire API is called to collect experimental data into various CSVs. This code processes and plots that raw data into the IB/IH scatter plots seen in the presentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title IMPORTS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shared\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "from scipy.stats import gaussian_kde\n",
    "import seaborn as sns\n",
    "\n",
    "# ignore depcrecation warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and filter the data\n",
    "def clean_df(df):\n",
    "    if 'source' not in df.columns: df['source'] = 'OUS'\n",
    "    if 'persona' not in df.columns: df['persona'] = ''\n",
    "    if 'stddev_score' not in df.columns: df['stddev_score'] = 0\n",
    "    df['persona'] = df['persona'].fillna('')\n",
    "    df['feature'] = df['feature'].fillna('')\n",
    "    df = df[(-0.8 < df['steerage']) & (df['steerage'] < 0.8)]\n",
    "    return df\n",
    "\n",
    "# Summarize the scores from the questions as two factors. \n",
    "# The Oxford Utilitarianism Scale has odd questions as coding for \"Impartial Beneficence\" and even as \"Instrumental Harm\",\n",
    "# each of which is a simple average of responses.\n",
    "def summarise_df(df):\n",
    "    sources = df['source'].unique()\n",
    "    questions = {\n",
    "        source: shared.get_questions(source)\n",
    "        for source in sources\n",
    "    }\n",
    "\n",
    "    df['factor'] = df.apply(lambda x: questions[x[\"source\"]][x[\"question\"]][\"type\"], axis=1)\n",
    "    df2 = df[['feature', 'steerage', 'persona', 'factor', 'mean_score', 'stddev_score']].groupby(['feature', 'steerage', 'persona', 'factor'], as_index=False).mean()\n",
    "    df2 = df2.pivot(index=['feature', 'steerage', 'persona'],columns='factor', values=['mean_score', 'stddev_score']).reset_index()\n",
    "    df2[\"IB\"] = df2[(\"mean_score\", \"IB\")]\n",
    "    df2[\"IH\"] = df2[(\"mean_score\", \"IH\")]\n",
    "    df2[\"IB_stddev\"] = df2[(\"stddev_score\", \"IB\")]\n",
    "    df2[\"IH_stddev\"] = df2[(\"stddev_score\", \"IH\")]\n",
    "    df2.drop(columns=[(\"mean_score\", \"IB\"), (\"mean_score\", \"IH\"), (\"stddev_score\", \"IB\"), (\"stddev_score\", \"IH\")], inplace=True)\n",
    "    return df2\n",
    "\n",
    "def get_df(*filenames, update=None):\n",
    "    df = pd.concat([pd.read_csv(filename) for filename in filenames])\n",
    "    if update:\n",
    "        df = update(df)\n",
    "    return summarise_df(clean_df(df))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title utilities for IH only / inverted IH questions\n",
    "\n",
    "# check for duplicates in the IH scale questions\n",
    "def check_IH_duplicate(df):\n",
    "\n",
    "    def filter_and_renumber(group):\n",
    "        if group['question'].nunique() > 39:\n",
    "            # Step 2: Delete 2nd question (0 indexed => question 1)\n",
    "            group = group[group['question'] != 1]\n",
    "            \n",
    "            # Step 3: Renumber the questions from 3-39 to 2-38\n",
    "            def renumber_questions(subgroup):\n",
    "                questions = subgroup['question'].values\n",
    "                questions = [q-1 if q >=2 else q for q in questions]\n",
    "                subgroup['question'] = questions\n",
    "                return subgroup\n",
    "            \n",
    "            group = group.groupby('feature').apply(renumber_questions).reset_index(drop=True)\n",
    "        return group\n",
    "\n",
    "    df = df.groupby(['feature', 'source']).apply(filter_and_renumber).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "# read csv and remocve duplicates if it is part of GGB_IHonly or GGB_invertedIH\n",
    "def read_and_check_duplicate_csv(filename):\n",
    "    df = check_IH_duplicate(pd.read_csv(filename))\n",
    "    return df\n",
    "\n",
    "def max_diff_by_feature(df):\n",
    "    #score_range = df.groupby(['question', 'feature', 'persona', 'source'])['mean_score'].agg(\n",
    "    score_range = df.groupby(['question', 'feature'])['mean_score'].agg(\n",
    "        score_diff=lambda x: x.max() - x.min()\n",
    "    ).reset_index()\n",
    "    return score_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tile HUMAN DATASET\n",
    "# Load and process the human dataset.\n",
    "h1 = pd.read_csv(\"ous_data/ous_align2.csv\")\n",
    "\n",
    "h2 = h1.copy()\n",
    "h2[\"IB\"] = (h2[\"IB1\"] + h2[\"IB2\"] + h2[\"IB3\"] + h2[\"IB4\"] + h2[\"IB5\"]) / 5\n",
    "h2[\"IH\"] = (h2[\"IH1\"] + h2[\"IH2\"] + h2[\"IH3\"] + h2[\"IH4\"]) / 4\n",
    "\n",
    "human_df = h2\n",
    "#h2 = h2[h2[\"country\"]==\"USA\"]\n",
    "\n",
    "#h2[[\"sex\", \"country\", \"age\", \"IB\", \"IH\"]][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title LOAD BASE MODELS \n",
    "def update(df):\n",
    "    def get_short_base(base):\n",
    "        return (base\n",
    "                .replace(\"meta-llama/\",\"\")\n",
    "                .replace(\"Meta-\", \"\")\n",
    "                .replace(\"Llama-\", \"\")\n",
    "                .replace(\"-Instruct\", \"\")\n",
    "        )\n",
    "    df[\"feature\"] = df.apply(lambda x: get_short_base(x[\"base\"])  + \" \" + x[\"source\"], axis=1)\n",
    "    return df\n",
    "\n",
    "base_df = get_df(\n",
    "    \"data/20241219172724_base70B_OUS.csv\",\n",
    "    \"data/20241219173023_base70B_GGB.csv\",\n",
    "    \"data/20241219173256_base8B_GGB.csv\",\n",
    "    \"data/20241219173351_base8B_OUS.csv\",\n",
    "    \"data/20241226183826_base70B33_OUS.csv\",\n",
    "    \"data/20250125170346base70B33_GGB.csv\",\n",
    "    update=update)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title STEERING results for \"moral\"\n",
    "\n",
    "# filenames\n",
    "moral_33_ggb = \"data/20250103153608_moral.csv\"\n",
    "moral_33 = 'data/20250114223758.csv'\n",
    "moral_31 = \"data/20241124001836.csv\"\n",
    "\n",
    "\n",
    "# load dataframe of 3.3 moral keywords (GGB)\n",
    "moral_33_ggb_df = get_df(moral_33_ggb)\n",
    "\n",
    "# load dataframe of 3.3 moral keywords results (OUS)\n",
    "moral_33_df = get_df(moral_33)\n",
    "\n",
    "# load dataframe of 3.1 moral keywords results(OUS)\n",
    "moral_31_df = get_df(moral_31)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title STEERING results for multiple keywords on GGB (3.3 70B)\n",
    "ggb_full_files = ['data/20250103153608_moral.csv', \n",
    "'data/20250117181646_altruism_updated.csv',\n",
    "'data/20250103231956_greater good.csv', \n",
    "'data/20250104023112_ethic.csv', \n",
    "'data/20250104055843_integrity.csv', \n",
    "'data/20250104091128_dignity.csv']\n",
    "\n",
    "# we're going to plot all of them in the same graph to make the point that IH is much harder to steer \n",
    "# than IB, and that the steering is consistent across different keywords\n",
    "# small point - we didn't filter the features so going to make it a list of dataframes\n",
    "ggb_max_score_ranges = [None]*len(ggb_full_files)\n",
    "for i,f in enumerate(ggb_full_files):\n",
    "    df = pd.read_csv(f)\n",
    "    ggb_max_score_ranges[i]= max_diff_by_feature(clean_df(df))\n",
    "    df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title  IH and inverted IH datasets (Base models)\n",
    "\n",
    "full_GGB_file = 'data/20250125170346base70B33_GGB.csv'\n",
    "GGB_inverted_file = 'data/20250119201457base70B33_GGB_inverted.csv'\n",
    "\n",
    "# load dataframe for 3.3 base (GGB) and get rid of IB but keep IH questions\n",
    "df_ggb = pd.read_csv(full_GGB_file)\n",
    "df_base_IH = df_ggb[df_ggb['question'] <40].copy()\n",
    "df_base_inverted = pd.read_csv(GGB_inverted_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title IH and inverted IH stering data\n",
    "GGB_IH_only_files = [\n",
    "    'data/GGB_IHonly20250121044426altruism.csv',\n",
    "    'data/GGB_IHonly20250121123957empathy.csv',\n",
    "    'data/GGB_IHonly20250121142449fairness.csv']\n",
    "\n",
    "GGB_inverted_files = [\n",
    "    'data/GGB_inverted20250121195539altruism.csv',\n",
    "    'data/GGB_inverted20250121182226empathy.csv',\n",
    "    'data/GGB_inverted20250121164933fairness.csv']\n",
    "\n",
    "# list of dfs for IH only and inverted IH questions (max diff steering scores)\n",
    "ggb_ih_only_max_scores = [max_diff_by_feature(clean_df(read_and_check_duplicate_csv(f))) for f in GGB_IH_only_files]   \n",
    "ggb_ih_invert_max_scores = [max_diff_by_feature(clean_df(read_and_check_duplicate_csv(f)))for f in GGB_inverted_files]\n",
    "\n",
    "# sanity check (number of unique questions and features)\n",
    "print([df['question'].nunique() for df in ggb_ih_only_max_scores], [df['question'].nunique() for df in ggb_ih_invert_max_scores])\n",
    "print([df['feature'].nunique() for df in ggb_ih_only_max_scores], [df['feature'].nunique() for df in ggb_ih_invert_max_scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scatter_plot_feature(feature, persona, group, fontsize=15, use_legend=False, use_lines=True, error_bars=True):\n",
    "    \"\"\"Group should have IB/IH columns and be in sorted order\"\"\"\n",
    "    # label the chart\n",
    "    has_persona = persona\n",
    "    has_feature = (group[\"steerage\"] != 0).any()\n",
    "    if has_persona and has_feature:\n",
    "        name = f\"{feature} ({persona})\"\n",
    "    elif has_persona:\n",
    "        name = persona\n",
    "    else:\n",
    "        name = feature\n",
    "    # Draw the actual dots\n",
    "    if error_bars:\n",
    "        sc = plt.errorbar(group['IB'], group['IH'], xerr=group[\"IB_stddev\"], yerr=group[\"IH_stddev\"],  marker='o',label=name)\n",
    "        color = sc[0].get_color()\n",
    "    else:\n",
    "        sc = plt.scatter(group['IB'], group['IH'],  marker='o',label=name)\n",
    "        color = sc.get_facecolor()\n",
    "    # Connect the dots. These are draw as arrows so it's clear which end of series\n",
    "    # is positive.\n",
    "    if use_lines:\n",
    "        for i in range(len(group) - 1):\n",
    "            plt.annotate(\n",
    "                '',  # No text for the annotation\n",
    "                xy=(group['IB'].iloc[i + 1], group['IH'].iloc[i + 1]),  # Arrow end\n",
    "                xytext=(group['IB'].iloc[i], group['IH'].iloc[i]),  # Arrow start\n",
    "                arrowprops=dict(arrowstyle='->', lw=1.5, color=color),  # Arrow style\n",
    "            )\n",
    "\n",
    "    if not use_legend:\n",
    "        plt.text(group['IB'].iloc[-1] + 0.04, group['IH'].iloc[-1], name, fontsize=fontsize, ha='left', va='center')\n",
    "\n",
    "def human_heatmap(human_df=h2):\n",
    "    # Draw humans a heatmap\n",
    "    ib_vals = np.arange(1, 8, 0.5)\n",
    "    ih_vals = np.arange(1, 8, 0.5)\n",
    "    heatmap, xedges, yedges = np.histogram2d(\n",
    "        human_df['IB'], human_df['IH'], bins=(ib_vals, ih_vals)\n",
    "    )\n",
    "    plt.pcolormesh(xedges, yedges, heatmap.T, cmap='viridis', shading='auto', alpha=0.3)\n",
    "\n",
    "def human_kde(human_df=h2, ax=None, alpha=1, colormap='Greys'):\n",
    "    # TODO: Not sure this is correct?\n",
    "    # Draw humans as KDE\n",
    "    smoothness=20\n",
    "    ib_vals = np.linspace(1, 7, smoothness)  # Smoother grid for IB\n",
    "    ih_vals = np.linspace(1, 7, smoothness)  # Smoother grid for IH\n",
    "    ib_grid, ih_grid = np.mgrid[1:7:(smoothness*1j), 1:7:(smoothness*1j)]\n",
    "    positions = np.vstack([ib_grid.ravel(), ih_grid.ravel()])\n",
    "    values = np.vstack([human_df['IB'], human_df['IH']])\n",
    "    #values = np.vstack([np.random.random(10000) * 3, np.random.random(10000) * 5])\n",
    "    kernel = gaussian_kde(values)\n",
    "    Z = np.reshape(kernel(positions).T, ib_vals.shape + ih_vals.shape)\n",
    "    if ax is None:\n",
    "        plt.imshow(np.rot90(Z), cmap=colormap, extent=[1, 7, 1, 7], alpha=alpha)\n",
    "    else:\n",
    "        ax.imshow(np.rot90(Z), cmap=colormap, extent=[1, 7, 1, 7], alpha=alpha)\n",
    "\n",
    "def make_plot(df2,\n",
    "              is_subplot=False,\n",
    "              heatmap=False,\n",
    "              title='Feature steerage effect on Instrumental Harm and Impartial Beneficence', \n",
    "              fontsize=15,\n",
    "              titlesize=20,\n",
    "              use_legend=False,\n",
    "              use_lines=True, human_df=h2):\n",
    "\n",
    "    if not is_subplot:\n",
    "         plt.figure(figsize=(10, 6))\n",
    "\n",
    "    if heatmap:\n",
    "        #human_heatmap(human_df=human_df)\n",
    "        human_kde(human_df=human_df)\n",
    "\n",
    "    for (feature, persona), group in df2.groupby(by=['feature', 'persona']):\n",
    "        scatter_plot_feature(feature, persona, group, fontsize, use_legend, use_lines)\n",
    "\n",
    "    # Add labels, legend, and grid\n",
    "    # plt.xlim(1, 7)\n",
    "    # plt.ylim(1, 7)\n",
    "    # plt.xticks(range(1, 8))  # Tick marks from 1 to 7\n",
    "    # plt.yticks(range(1, 8))  # Tick marks from 1 to 7\n",
    "    plt.xlabel('Impartial Beneficence', fontsize=titlesize)\n",
    "    plt.ylabel('Instrumental Harm', fontsize=titlesize)\n",
    "    plt.title(title, fontsize=titlesize)\n",
    "    if use_legend:\n",
    "        plt.legend(loc=\"upper left\")\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Show plot\n",
    "    if not is_subplot:\n",
    "        plt.show()\n",
    "\n",
    "def chunks(xs, n):\n",
    "    n = max(1, n)\n",
    "    return (xs[i:i+n] for i in range(0, len(xs), n))\n",
    "\n",
    "def do_plots(df2, chunkby=5, *args, **kwargs):\n",
    "    # TODO: Sort features by shape?\n",
    "    all_features = df2[\"feature\"].unique()\n",
    "    for features in chunks(all_features, chunkby):\n",
    "        make_plot(df2[df2[\"feature\"].isin(features)], *args, **kwargs)\n",
    "\n",
    "if False:\n",
    "    baseline_df = get_df(baseline_models)\n",
    "    h_mean = h2.agg(dict(IH='mean', IB='mean'))\n",
    "    df = pd.DataFrame([dict(factor=0, feature='Human Mean', steerage=0, persona=\"\", IB=h_mean['IB'], IH=h_mean['IH'])])\n",
    "    df = pd.concat([df, baseline_df])\n",
    "    print(df)\n",
    "    make_plot(df, is_subplot=True, heatmap=True, title=\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_steepest(df,n=5, sortby=\"mag\", coeff_range=0.1):\n",
    "    # coeff_range is the range of steering coefficients to consider when looking at differences (e.g. 0.5 means consider the range -0.5 to 0.5)\n",
    "    x = df.pivot(columns=\"steerage\", index=[\"feature\", \"persona\"])\n",
    "    ib = (x[(\"IB\", coeff_range)] - x[(\"IB\", -coeff_range)]) / 0.2\n",
    "    ih = (x[(\"IH\", coeff_range)] - x[(\"IH\", -coeff_range)]) / 0.2\n",
    "    slope = pd.DataFrame({'IB': ib, 'IH': ih})\n",
    "    slope[\"mag\"] = (slope[\"IB\"]**2+slope[\"IH\"]**2)**0.5\n",
    "    slope[\"IB\"] = slope[\"IB\"].abs()\n",
    "    slope[\"IH\"] = slope[\"IH\"].abs()\n",
    "    slope = slope.sort_values(sortby,ascending=False)\n",
    "    best = slope[:n].reset_index()[\"feature\"]\n",
    "    return df[df[\"feature\"].isin(best)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def steering_lines(df_slice, name, ax):\n",
    "    #lw = 3\n",
    "    #sc = ax.errorbar(df_slice['IB'], df_slice['IH'], xerr=df_slice[\"IB_stddev\"], yerr=df_slice[\"IH_stddev\"],  marker='o', markersize=2 ,label=name)\n",
    "    #color = sc[0].get_color()\n",
    "    sc = ax.scatter(df_slice['IB'], df_slice['IH'], marker='o', s=2 ,label=name)\n",
    "    color = sc.get_facecolor()\n",
    "    for i in range(len(df_slice) - 1):\n",
    "            ax.annotate(\n",
    "                '',  # No text for the annotation\n",
    "                xy=(df_slice['IB'].iloc[i + 1], df_slice['IH'].iloc[i + 1]),  # Arrow end\n",
    "                xytext=(df_slice['IB'].iloc[i], df_slice['IH'].iloc[i]),  # Arrow start\n",
    "                arrowprops=dict(arrowstyle='-|>', color=color,shrinkA=0, shrinkB=0)  # Arrow style\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title PLOTTING PARAMETERS (defaults)\n",
    "\n",
    "# Set the default font size for plots\n",
    "text_size = 9\n",
    "plt.rcParams.update({\n",
    "    'font.size': text_size,        # Base font size\n",
    "    'axes.titlesize': text_size,   # Title\n",
    "    'axes.labelsize': text_size,   # Axis labels\n",
    "    'xtick.labelsize': text_size,  # X tick labels\n",
    "    'ytick.labelsize': text_size,  # Y tick labels\n",
    "    'legend.fontsize': text_size,  # Legend\n",
    "    'figure.titlesize': text_size,  # Figure title\n",
    "    'lines.linewidth': 1.0,      # Line width\n",
    "})\n",
    "# Axis style (get rid of top and right)\n",
    "plt.rcParams['axes.spines.top'] = False # remove the top line\n",
    "plt.rcParams['axes.spines.right'] = False # remove the right line\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title FIGURE 1 : base models v human data\n",
    "fig, ax = plt.subplots(1,1)\n",
    "fig.set_size_inches(3, 3, forward=False)\n",
    "\n",
    "\n",
    "colors = plt.cm.Greys(np.linspace(0.01,1, 256))\n",
    "custom_grey = LinearSegmentedColormap.from_list('custom_grey', colors)\n",
    "\n",
    "\n",
    "human_kde(human_df=human_df, colormap=custom_grey)\n",
    "\n",
    "for (base_model, _), group in base_df.groupby(by=['feature', 'persona']):\n",
    "        # PLOT THE BASE MODEL DATA\n",
    "        plt.errorbar(group['IB'], group['IH'], xerr=group[\"IB_stddev\"], yerr=group[\"IH_stddev\"],  marker='o',label=base_model)\n",
    "        # ANNOTATE THE DATA POINTS\n",
    "        x, y = group['IB'].values, group['IH'].values # get data point\n",
    "        if base_model == '3.3-70B OUS':\n",
    "               plt.annotate(base_model, (x, y + 0.1)) \n",
    "        elif base_model == '3.1-70B GGB':\n",
    "                plt.annotate(base_model, (x - 1.75, y - 0.3))\n",
    "        elif base_model == '3.3-70B GGB':\n",
    "                plt.annotate(base_model, (x, y - 0.3))\n",
    "        else:\n",
    "                plt.annotate(base_model, (x, y + 0.1))\n",
    "ax.set_ylim(1, 6)\n",
    "plt.xlabel('Impartial Beneficence')\n",
    "plt.ylabel('Instrumental Harm')\n",
    "plt.title('Base Models vs Human Data (KDE)')\n",
    "\n",
    "plt.savefig('figures/Figure1.pdf', bbox_inches='tight')\n",
    "plt.savefig('figures/Figure1.png', bbox_inches='tight', dpi=600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Figure 2 : 3.1 steerability v 3.3 steerability\n",
    "\n",
    "moral_31_feats = moral_31_df['feature'].unique()\n",
    "moral_33_feats = moral_33_df['feature'].unique()\n",
    "moral_33_ggb_feats = moral_33_ggb_df['feature'].unique()\n",
    "\n",
    "fig, ax = plt.subplots(1,3)\n",
    "fig.set_size_inches(7, 7/3, forward=False)\n",
    "\n",
    "#ax[0] = plt.subplot(2, 1, 1)\n",
    "kdealpha = 1\n",
    "\n",
    "human_kde(human_df=human_df, ax=ax[0], alpha=kdealpha)\n",
    "for feature in moral_31_feats:\n",
    "    df_slice = moral_31_df[moral_31_df['feature'] == feature]\n",
    "    steering_lines(df_slice, feature, ax[0])\n",
    "\n",
    "human_kde(human_df=human_df, ax=ax[1], alpha=kdealpha)\n",
    "for feature in moral_33_feats:\n",
    "    df_slice = moral_33_df[moral_33_df['feature'] == feature]\n",
    "    steering_lines(df_slice, feature, ax[1])\n",
    "\n",
    "human_kde(human_df=human_df, ax=ax[2], alpha=kdealpha)\n",
    "for feature in moral_33_ggb_feats:\n",
    "    df_slice = moral_33_ggb_df[moral_33_ggb_df['feature'] == feature]\n",
    "    steering_lines(df_slice, feature, ax[2])\n",
    "\n",
    "\n",
    "ax[0].title.set_text('3.1-70B (OUS)')\n",
    "ax[1].title.set_text('3.3-70B (OUS)')\n",
    "ax[2].title.set_text('3.3-70B (GGB)')\n",
    "\n",
    "ax[1].set_xlabel('Impartial Beneficence')\n",
    "ax[0].set_ylabel('Instrumental Harm')\n",
    "ax[0].set_aspect('equal')\n",
    "ax[1].set_aspect('equal')\n",
    "ax[2].set_aspect('equal')\n",
    "ax[1].set_yticklabels([])\n",
    "ax[2].set_yticklabels([])\n",
    "\n",
    "plt.savefig('figures/Figure2.pdf', bbox_inches='tight')\n",
    "plt.savefig('figures/Figure2.png', bbox_inches='tight', dpi=600)\n",
    "# for a in ax:\n",
    "#     a.set_ylim(1, 7)\n",
    "#     a.set_xlim(1, 7)\n",
    "#make_plot(moral_31_df, is_subplot=True, heatmap=True, title=\"3.1 Steerability\", use_legend=True, use_lines=False, human_df=h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Figure 3 : 3.3 max steerability by question (GGB full)\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "fig.set_size_inches(7,3, forward=False)\n",
    "nfeats=0\n",
    "\n",
    "for score_range in ggb_max_score_ranges:\n",
    "    nfeats += (len(score_range['feature'].unique()))\n",
    "    for feature in score_range['feature'].unique():\n",
    "        mask = score_range['feature'] == feature\n",
    "        plt.scatter(score_range[mask]['question']+1, \n",
    "                    score_range[mask]['score_diff'],\n",
    "                    marker='o',\n",
    "                    s=5,\n",
    "                    label=feature, alpha=0.2, color='black')\n",
    "\n",
    "plt.legend().remove() \n",
    "plt.xlabel('Question')\n",
    "plt.ylabel('Max score difference')  \n",
    "title_str = (f'GGB max steerability by question ({nfeats} features)')\n",
    "plt.title(title_str)\n",
    "\n",
    "# Get x-tick labels\n",
    "q_ticks = np.arange(0,100,10)\n",
    "q_ticks[0] =1\n",
    "ax.set_xticks(q_ticks)\n",
    "labels = ax.get_xticklabels()\n",
    "\n",
    "# Color specific labels\n",
    "for label in labels:\n",
    "    if float(label.get_text())<= 40:\n",
    "        label.set_color('red')\n",
    "    else:\n",
    "        label.set_color('black')\n",
    "\n",
    "plt.savefig('figures/Figure3.pdf', bbox_inches='tight')\n",
    "plt.savefig('figures/Figure3.png', bbox_inches='tight', dpi=600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 4 : 3.3 GGH IH only vs inverted IH (base)\n",
    "fig, ax = plt.subplots(1,1)\n",
    "fig.set_size_inches(7, 3, forward=False)\n",
    "\n",
    "# Plot the IH only data\n",
    "ax.errorbar(df_base_IH['question'], df_base_IH['mean_score'],\n",
    "                yerr=df_base_IH['stddev_score'],fmt='ko', label='GGB original', alpha=0.7) \n",
    "ax.errorbar(df_base_inverted['question'], df_base_inverted['mean_score'],\n",
    "                yerr=df_base_inverted['stddev_score'],fmt='ro', label='GGB inverted', alpha=0.7) \n",
    "plt.grid(False)\n",
    "\n",
    "ax.set_ylim(-0.5,9.25)\n",
    "ax.set_yticks(np.arange(1,8))\n",
    "plt.xlabel('Question')\n",
    "plt.ylabel('Mean IH Score')\n",
    "plt.title('70B 3.3 responses to original and inverted instrumental harm questions')\n",
    "plt.legend(loc='upper left', bbox_to_anchor=None, frameon=True, ncol=2)\n",
    "\n",
    "plt.savefig('figures/Figure4.pdf', bbox_inches='tight')\n",
    "plt.savefig('figures/Figure4.png', bbox_inches='tight', dpi=600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 5 : 3.3 GGH IH only vs inverted IH (steerability)\n",
    "\n",
    "fig, ax = plt.subplots(2,1)\n",
    "\n",
    "# hard coded right now (see sanity check above)\n",
    "nfeats=30\n",
    "\n",
    "ax[0] = plt.subplot(2, 1, 1)\n",
    "for score_range in ggb_ih_only_max_scores:\n",
    "    for feature in score_range['feature'].unique():\n",
    "        mask = score_range['feature'] == feature\n",
    "        plt.scatter(score_range[mask]['question']+1, \n",
    "                    score_range[mask]['score_diff'],\n",
    "                    marker='o',\n",
    "                    s=8, \n",
    "                    label=feature, alpha=0.2, color='black')\n",
    "\n",
    "plt.legend().remove() \n",
    "\n",
    "ax[1] = plt.subplot(2, 1, 2)\n",
    "for score_range in ggb_ih_invert_max_scores:\n",
    "    for feature in score_range['feature'].unique():\n",
    "        mask = score_range['feature'] == feature\n",
    "        plt.scatter(score_range[mask]['question']+1, \n",
    "                    score_range[mask]['score_diff'],\n",
    "                    marker='o',\n",
    "                    s=8,\n",
    "                    label=feature, alpha=0.2, color='red')\n",
    "\n",
    "plt.legend().remove() \n",
    "\n",
    "\n",
    "plt.xlabel('Question')\n",
    "plt.ylabel('Max score difference')  \n",
    "title_str = (f'IH steerability by question ({nfeats} features)')\n",
    "plt.suptitle(title_str)\n",
    "\n",
    "# Get x-tick labels\n",
    "q_ticks = np.arange(0,45,5)\n",
    "q_ticks[0] =1\n",
    "ax[0].set_ylim(-0.3, 5.5)\n",
    "#ax[0].set_yticks([0, 1, 2])\n",
    "ax[1].set_ylim(-0.3 , 5.5)\n",
    "ax[0].set_xticks(q_ticks)\n",
    "ax[0].set_xticklabels([]) \n",
    "ax[1].set_xticks(q_ticks)\n",
    "\n",
    "# axis tittles\n",
    "ax[0].set_title('GGB original')\n",
    "ax[1].set_title('GGB inverted',  color='firebrick')\n",
    "\n",
    "plt.savefig('figures/Figure5.pdf', bbox_inches='tight')\n",
    "plt.savefig('figures/Figure5.png', bbox_inches='tight', dpi=600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
