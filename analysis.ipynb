{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In `main.ipynb` the goodfire API is called to collect experimental data into various CSVs. This code processes and plots that raw data into the IB/IH scatter plots seen in the presentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base</th>\n",
       "      <th>source</th>\n",
       "      <th>feature</th>\n",
       "      <th>steerage</th>\n",
       "      <th>persona</th>\n",
       "      <th>question</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>stddev_score</th>\n",
       "      <th>score</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>meta-llama/Llama-3.3-70B-Instruct</td>\n",
       "      <td>GGB_inverted</td>\n",
       "      <td>Altruistic and selfless behavior or intentions</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6.999998</td>\n",
       "      <td>0.003566</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>meta-llama/Llama-3.3-70B-Instruct</td>\n",
       "      <td>GGB_inverted</td>\n",
       "      <td>Altruistic and selfless behavior or intentions</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6.999999</td>\n",
       "      <td>0.001723</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>meta-llama/Llama-3.3-70B-Instruct</td>\n",
       "      <td>GGB_inverted</td>\n",
       "      <td>Altruistic and selfless behavior or intentions</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>6.999999</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                base        source  \\\n",
       "0  meta-llama/Llama-3.3-70B-Instruct  GGB_inverted   \n",
       "1  meta-llama/Llama-3.3-70B-Instruct  GGB_inverted   \n",
       "2  meta-llama/Llama-3.3-70B-Instruct  GGB_inverted   \n",
       "\n",
       "                                          feature  steerage  persona  \\\n",
       "0  Altruistic and selfless behavior or intentions      -0.5      NaN   \n",
       "1  Altruistic and selfless behavior or intentions      -0.5      NaN   \n",
       "2  Altruistic and selfless behavior or intentions      -0.5      NaN   \n",
       "\n",
       "   question  mean_score  stddev_score  score  text  \n",
       "0         0    6.999998      0.003566      7     7  \n",
       "1         1    6.999999      0.001723      7     7  \n",
       "2         2    6.999999      0.001713      7     7  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Some of the experiments run\n",
    "moral_factors = \"data/GGB_inverted20250120112538altruism.csv\" #\"data/20250117181646_altruism_updated.csv\"\n",
    "personas_test = \"data/personas_test.csv\"\n",
    "baseline_models = \"data/baseline_models.csv\"\n",
    "elephant_features = \"data/elephant_features.csv\"\n",
    "personas_nationality = 'data/20241124101056nationalities.csv'\n",
    "personas_ages = 'data/20241124101116ages.csv'\n",
    "personas_gender = 'data/20241124101127genders.csv'\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(moral_factors)\n",
    "df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factor: ['IH']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "('mean_score', 'IB')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/GitHub/reprogramming-ai-models/.venv/lib/python3.13/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'IB'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32mindex.pyx:768\u001b[0m, in \u001b[0;36mpandas._libs.index.BaseMultiIndexCodesEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/GitHub/reprogramming-ai-models/.venv/lib/python3.13/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'IB'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/GitHub/reprogramming-ai-models/.venv/lib/python3.13/site-packages/pandas/core/indexes/multi.py:3053\u001b[0m, in \u001b[0;36mMultiIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3052\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3053\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3054\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:771\u001b[0m, in \u001b[0;36mpandas._libs.index.BaseMultiIndexCodesEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ('mean_score', 'IB')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 68\u001b[0m\n\u001b[1;32m     65\u001b[0m         df \u001b[38;5;241m=\u001b[39m update(df)\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m summarise_df(clean_df(df))\n\u001b[0;32m---> 68\u001b[0m df2 \u001b[38;5;241m=\u001b[39m \u001b[43msummarise_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclean_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# df2.head(40)\u001b[39;00m\n\u001b[1;32m     70\u001b[0m df2\n",
      "Cell \u001b[0;32mIn[2], line 55\u001b[0m, in \u001b[0;36msummarise_df\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     47\u001b[0m df2 \u001b[38;5;241m=\u001b[39m df2\u001b[38;5;241m.\u001b[39mpivot(index\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msteerage\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpersona\u001b[39m\u001b[38;5;124m'\u001b[39m],columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfactor\u001b[39m\u001b[38;5;124m'\u001b[39m, values\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_score\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstddev_score\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Enables full cell output when printing df\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# pd.set_option('display.max_columns', None)\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# pd.set_option('display.max_rows', None)\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# df2 = df2.pivot(index=['feature', 'steerage', 'persona'], columns='factor', values=['mean_score', 'stddev_score'])\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m df2[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIB\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf2\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean_score\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mIB\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     56\u001b[0m df2[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIH\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df2[(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_score\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIH\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m     57\u001b[0m df2[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIB_stddev\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df2[(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstddev_score\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIB\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n",
      "File \u001b[0;32m~/Documents/GitHub/reprogramming-ai-models/.venv/lib/python3.13/site-packages/pandas/core/frame.py:4101\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_single_key:\n\u001b[1;32m   4100\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m-> 4101\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_multilevel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4102\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n",
      "File \u001b[0;32m~/Documents/GitHub/reprogramming-ai-models/.venv/lib/python3.13/site-packages/pandas/core/frame.py:4159\u001b[0m, in \u001b[0;36mDataFrame._getitem_multilevel\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_getitem_multilevel\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m   4158\u001b[0m     \u001b[38;5;66;03m# self.columns is a MultiIndex\u001b[39;00m\n\u001b[0;32m-> 4159\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4160\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loc, (\u001b[38;5;28mslice\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray)):\n\u001b[1;32m   4161\u001b[0m         new_columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns[loc]\n",
      "File \u001b[0;32m~/Documents/GitHub/reprogramming-ai-models/.venv/lib/python3.13/site-packages/pandas/core/indexes/multi.py:3055\u001b[0m, in \u001b[0;36mMultiIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3053\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   3054\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3055\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3056\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3057\u001b[0m     \u001b[38;5;66;03m# e.g. test_partial_slicing_with_multiindex partial string slicing\u001b[39;00m\n\u001b[1;32m   3058\u001b[0m     loc, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_loc_level(key, \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnlevels)))\n",
      "\u001b[0;31mKeyError\u001b[0m: ('mean_score', 'IB')"
     ]
    }
   ],
   "source": [
    "import shared, pprint\n",
    "\n",
    "# Clean and filter the data\n",
    "def clean_df(df):\n",
    "    if 'source' not in df.columns: df['source'] = 'OUS'\n",
    "    if 'persona' not in df.columns: df['persona'] = ''\n",
    "    if 'stddev_score' not in df.columns: df['stddev_score'] = 0\n",
    "    df['persona'] = df['persona'].fillna('')\n",
    "    df['feature'] = df['feature'].fillna('')\n",
    "    df = df[(-0.8 < df['steerage']) & (df['steerage'] < 0.8)]\n",
    "    return df\n",
    "\n",
    "# Summarize the scores from the questions as two factors. \n",
    "# The Oxford Utilitarianism Scale has odd questions as coding for \"Impartial Beneficence\" and even as \"Instrumental Harm\",\n",
    "# each of which is a simple average of responses.\n",
    "def summary_by_feat_df(df):\n",
    "    sources = df['source'].unique()\n",
    "    questions = {\n",
    "        source: shared.get_questions(source)\n",
    "        for source in sources\n",
    "    }\n",
    "    # df['factor'] = df.apply(lambda x: questions[x[\"source\"]][x[\"question\"]][\"type\"], axis=1)\n",
    "    df2 = df[['feature', 'steerage', 'persona', 'mean_score', 'stddev_score']].groupby(['feature', 'question', 'persona'], as_index=False)\n",
    "    df2 = df2.pivot(index=['feature', 'steerage', 'persona'],columns='factor', values=['mean_score', 'stddev_score']).reset_index()\n",
    "    # df2[\"IB\"] = df2[(\"mean_score\", \"IB\")]\n",
    "    # df2[\"IH\"] = df2[(\"mean_score\", \"IH\")]\n",
    "    # df2[\"IB_stddev\"] = df2[(\"stddev_score\", \"IB\")]\n",
    "    # df2[\"IH_stddev\"] = df2[(\"stddev_score\", \"IH\")]\n",
    "    df2.drop(columns=[(\"mean_score\", \"IB\"), (\"mean_score\", \"IH\"), (\"stddev_score\", \"IB\"), (\"stddev_score\", \"IH\")], inplace=True)\n",
    "    return df2\n",
    "\n",
    "\n",
    "def summarise_df(df):\n",
    "    sources = df['source'].unique()\n",
    "    questions = {\n",
    "        source: shared.get_questions(source)\n",
    "        for source in sources\n",
    "    }\n",
    "    # print('---------')\n",
    "    # pprint.pprint(questions)\n",
    "    # print('-----------')\n",
    "\n",
    "    df['factor'] = df.apply(lambda x: questions[x[\"source\"]][x[\"question\"]][\"type\"], axis=1)\n",
    "    print('Factor:', df['factor'].unique())\n",
    "    \n",
    "    df2 = df[['feature', 'steerage', 'persona', 'factor', 'mean_score', 'stddev_score']].groupby(['feature', 'steerage', 'persona', 'factor'], as_index=False).mean()\n",
    "    df2 = df2.pivot(index=['feature', 'steerage', 'persona'],columns='factor', values=['mean_score', 'stddev_score']).reset_index()\n",
    "\n",
    "    # Enables full cell output when printing df\n",
    "    # pd.set_option('display.max_columns', None)\n",
    "    # pd.set_option('display.max_rows', None)\n",
    "\n",
    "    # df2 = df2.pivot(index=['feature', 'steerage', 'persona'], columns='factor', values=['mean_score', 'stddev_score'])\n",
    "\n",
    "    #df2[\"IB\"] = df2[(\"mean_score\", \"IB\")]\n",
    "    df2[\"IH\"] = df2[(\"mean_score\", \"IH\")]\n",
    "    #df2[\"IB_stddev\"] = df2[(\"stddev_score\", \"IB\")]\n",
    "    df2[\"IH_stddev\"] = df2[(\"stddev_score\", \"IH\")]\n",
    "    #df2.drop(columns=[(\"mean_score\", \"IB\"), (\"mean_score\", \"IH\"), (\"stddev_score\", \"IB\"), (\"stddev_score\", \"IH\")], inplace=True)\n",
    "    df2.drop(columns=[(\"mean_score\", \"IH\"), (\"stddev_score\", \"IH\")], inplace=True)\n",
    "    return df2\n",
    "\n",
    "def get_df(*filenames, update=None):\n",
    "    df = pd.concat([pd.read_csv(filename) for filename in filenames])\n",
    "    if update:\n",
    "        df = update(df)\n",
    "    return summarise_df(clean_df(df))\n",
    "\n",
    "df2 = summarise_df(clean_df(df))\n",
    "# df2.head(40)\n",
    "df2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def summary_by_feat_2_plt(df):\n",
    "    score_range = df.groupby(['question', 'feature', 'persona', 'source'])['mean_score'].agg(\n",
    "    # score_range = df.groupby(['question', 'feature'])['mean_score'].agg(\n",
    "        score_diff=lambda x: x.max() - x.min()\n",
    "    ).reset_index()\n",
    "    return score_range\n",
    "\n",
    "score_range = summary_by_feat_2_plt(clean_df(df))\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Create line plot with different color for each feature\n",
    "sns.lineplot(data=score_range,\n",
    "                x='question',\n",
    "                y='score_diff',\n",
    "                hue='feature',\n",
    "                marker='o')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Max-Min Meanscore Difference by Question and Feature')\n",
    "plt.xlabel('Question Number')\n",
    "plt.ylabel('Max-Min Meanscore Difference')\n",
    "\n",
    "# Rotate x-axis labels if needed\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Adjust layout to prevent label cutoff\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add legend outside of plot area\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', title='Features');\n",
    "\n",
    "# plt.gcf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load and process the human dataset.\n",
    "h1 = pd.read_csv(\"ous_data/ous_align2.csv\")\n",
    "\n",
    "\n",
    "h2 = h1.copy()\n",
    "h2[\"IB\"] = (h2[\"IB1\"] + h2[\"IB2\"] + h2[\"IB3\"] + h2[\"IB4\"] + h2[\"IB5\"]) / 5\n",
    "h2[\"IH\"] = (h2[\"IH1\"] + h2[\"IH2\"] + h2[\"IH3\"] + h2[\"IH4\"]) / 4\n",
    "\n",
    "#h2 = h2[h2[\"country\"]==\"USA\"]\n",
    "\n",
    "#h2[[\"sex\", \"country\", \"age\", \"IB\", \"IH\"]][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "def scatter_plot_feature(feature, persona, group, fontsize=15, use_legend=False, use_lines=True, error_bars=True):\n",
    "    \"\"\"Group should have IB/IH columns and be in sorted order\"\"\"\n",
    "    # label the chart\n",
    "    has_persona = persona\n",
    "    has_feature = (group[\"steerage\"] != 0).any()\n",
    "    if has_persona and has_feature:\n",
    "        name = f\"{feature} ({persona})\"\n",
    "    elif has_persona:\n",
    "        name = persona\n",
    "    else:\n",
    "        name = feature\n",
    "    # Draw the actual dots\n",
    "    if error_bars:\n",
    "        sc = plt.errorbar(group['IB'], group['IH'], xerr=group[\"IB_stddev\"], yerr=group[\"IH_stddev\"],  marker='o',label=name)\n",
    "        color = sc[0].get_color()\n",
    "    else:\n",
    "        sc = plt.scatter(group['IB'], group['IH'],  marker='o',label=name)\n",
    "        color = sc.get_facecolor()\n",
    "    # Connect the dots. These are draw as arrows so it's clear which end of series\n",
    "    # is positive.\n",
    "    if use_lines:\n",
    "        for i in range(len(group) - 1):\n",
    "            plt.annotate(\n",
    "                '',  # No text for the annotation\n",
    "                xy=(group['IB'].iloc[i + 1], group['IH'].iloc[i + 1]),  # Arrow end\n",
    "                xytext=(group['IB'].iloc[i], group['IH'].iloc[i]),  # Arrow start\n",
    "                arrowprops=dict(arrowstyle='->', lw=1.5, color=color),  # Arrow style\n",
    "            )\n",
    "\n",
    "    if not use_legend:\n",
    "        plt.text(group['IB'].iloc[-1] + 0.04, group['IH'].iloc[-1], name, fontsize=fontsize, ha='left', va='center')\n",
    "\n",
    "def human_heatmap(human_df=h2):\n",
    "    # Draw humans a heatmap\n",
    "    ib_vals = np.arange(1, 8, 0.5)\n",
    "    ih_vals = np.arange(1, 8, 0.5)\n",
    "    heatmap, xedges, yedges = np.histogram2d(\n",
    "        human_df['IB'], human_df['IH'], bins=(ib_vals, ih_vals)\n",
    "    )\n",
    "    plt.pcolormesh(xedges, yedges, heatmap.T, cmap='viridis', shading='auto', alpha=0.3)\n",
    "\n",
    "def human_kde(human_df=h2):\n",
    "    # TODO: Not sure this is correct?\n",
    "    # Draw humans as KDE\n",
    "    smoothness=20\n",
    "    ib_vals = np.linspace(1, 7, smoothness)  # Smoother grid for IB\n",
    "    ih_vals = np.linspace(1, 7, smoothness)  # Smoother grid for IH\n",
    "    ib_grid, ih_grid = np.mgrid[1:7:(smoothness*1j), 1:7:(smoothness*1j)]\n",
    "    positions = np.vstack([ib_grid.ravel(), ih_grid.ravel()])\n",
    "    values = np.vstack([human_df['IB'], human_df['IH']])\n",
    "    #values = np.vstack([np.random.random(10000) * 3, np.random.random(10000) * 5])\n",
    "    kernel = gaussian_kde(values)\n",
    "    Z = np.reshape(kernel(positions).T, ib_vals.shape + ih_vals.shape)\n",
    "\n",
    "    plt.imshow(np.rot90(Z), cmap=plt.cm.gist_earth_r, extent=[1, 7, 1, 7])\n",
    "\n",
    "def make_plot(df2,\n",
    "              is_subplot=False,\n",
    "              heatmap=False,\n",
    "              title='Feature steerage effect on Instrumental Harm and Impartial Beneficence', \n",
    "              fontsize=15,\n",
    "              titlesize=20,\n",
    "              use_legend=False,\n",
    "              use_lines=True, human_df=h2):\n",
    "\n",
    "    if not is_subplot:\n",
    "         plt.figure(figsize=(10, 6))\n",
    "\n",
    "    if heatmap:\n",
    "        #human_heatmap(human_df=human_df)\n",
    "        human_kde(human_df=human_df)\n",
    "\n",
    "    for (feature, persona), group in df2.groupby(by=['feature', 'persona']):\n",
    "        scatter_plot_feature(feature, persona, group, fontsize, use_legend, use_lines)\n",
    "\n",
    "    # Add labels, legend, and grid\n",
    "    # plt.xlim(1, 7)\n",
    "    # plt.ylim(1, 7)\n",
    "    # plt.xticks(range(1, 8))  # Tick marks from 1 to 7\n",
    "    # plt.yticks(range(1, 8))  # Tick marks from 1 to 7\n",
    "    plt.xlabel('Impartial Beneficence', fontsize=titlesize)\n",
    "    plt.ylabel('Instrumental Harm', fontsize=titlesize)\n",
    "    plt.title(title, fontsize=titlesize)\n",
    "    if use_legend:\n",
    "        plt.legend(loc=\"upper left\")\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Show plot\n",
    "    if not is_subplot:\n",
    "        plt.show()\n",
    "\n",
    "def chunks(xs, n):\n",
    "    n = max(1, n)\n",
    "    return (xs[i:i+n] for i in range(0, len(xs), n))\n",
    "\n",
    "def do_plots(df2, chunkby=5, *args, **kwargs):\n",
    "    # TODO: Sort features by shape?\n",
    "    all_features = df2[\"feature\"].unique()\n",
    "    for features in chunks(all_features, chunkby):\n",
    "        make_plot(df2[df2[\"feature\"].isin(features)], *args, **kwargs)\n",
    "\n",
    "if False:\n",
    "    baseline_df = get_df(baseline_models)\n",
    "    h_mean = h2.agg(dict(IH='mean', IB='mean'))\n",
    "    df = pd.DataFrame([dict(factor=0, feature='Human Mean', steerage=0, persona=\"\", IB=h_mean['IB'], IH=h_mean['IH'])])\n",
    "    df = pd.concat([df, baseline_df])\n",
    "    print(df)\n",
    "    make_plot(df, is_subplot=True, heatmap=True, title=\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_steepest(df,n=5, sortby=\"mag\"):\n",
    "\n",
    "    x = df.pivot(columns=\"steerage\", index=[\"feature\", \"persona\"])\n",
    "    ib = (x[(\"IB\", 0.1)] - x[(\"IB\", -0.1)]) / 0.2\n",
    "    ih = (x[(\"IH\", 0.1)] - x[(\"IH\", -0.1)]) / 0.2\n",
    "    slope = pd.DataFrame({'IB': ib, 'IH': ih})\n",
    "    slope[\"mag\"] = (slope[\"IB\"]**2+slope[\"IH\"]**2)**0.5\n",
    "    slope[\"IB\"] = slope[\"IB\"].abs()\n",
    "    slope[\"IH\"] = slope[\"IH\"].abs()\n",
    "    slope = slope.sort_values(sortby,ascending=False)\n",
    "    best = slope[:n].reset_index()[\"feature\"]\n",
    "    return df[df[\"feature\"].isin(best)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compares the base models vs various subsetes of the human data\n",
    "if False:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    def update(df):\n",
    "        def get_short_base(base):\n",
    "            return (base\n",
    "                    .replace(\"meta-llama/\",\"\")\n",
    "                    .replace(\"Meta-\", \"\")\n",
    "                    .replace(\"Llama-\", \"\")\n",
    "                    .replace(\"-Instruct\", \"\")\n",
    "            )\n",
    "        df[\"feature\"] = df.apply(lambda x: get_short_base(x[\"base\"])  + \" \" + x[\"source\"], axis=1)\n",
    "        return df\n",
    "\n",
    "    df = get_df(\n",
    "        \"data/20241219172724_base70B_OUS.csv\",\n",
    "        \"data/20241219173023_base70B_GGB.csv\",\n",
    "        \"data/20241219173256_base8B_GGB.csv\",\n",
    "        \"data/20241219173351_base8B_OUS.csv\",\n",
    "        \"data/20241226183826_base70B33_OUS.csv\",\n",
    "        update=update\n",
    "    )\n",
    "\n",
    "    plt.sca(axes[0])\n",
    "    make_plot(df, is_subplot=True, heatmap=True, title=\"Base Models vs Humans\")\n",
    "    plt.sca(axes[1])\n",
    "    make_plot(df, is_subplot=True, heatmap=True, title=\"Base Models vs Americans\", human_df=h2[h2[\"country\"] == \"USA\"])\n",
    "    plt.sca(axes[2])\n",
    "    make_plot(df, is_subplot=True, heatmap=True, title=\"Base Models vs Russians\", human_df=h2[h2[\"country\"] == \"RUS\"])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots nationality personas\n",
    "\n",
    "from shared import nationality_to_continent\n",
    "if False:    \n",
    "    pn = get_df(personas_nationality)\n",
    "    pc = pn.copy()\n",
    "    pc[\"persona\"] = pc[\"persona\"].map(nationality_to_continent)\n",
    "\n",
    "    make_plot(pc, is_subplot=True, heatmap=True, use_lines=False, use_legend=True, title=\"Country personas\")\n",
    "    labels = [\"American\", \"Russian\", \"Chinese\", \"Singaporean\"]\n",
    "    for label in labels:\n",
    "        row = pn[pn[\"persona\"] == label]\n",
    "        plt.text(row['IB'].iloc[-1] + 0.04, row['IH'].iloc[-1] + 0.6, label, fontsize=12, ha='left', va='center', rotation=50, color=\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender personas\n",
    "if False:\n",
    "    do_plots(get_df(personas_gender), title=\"Gender\", heatmap=True, fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's useful to include some pointless features as even these move the rating in extreme cases. But they have very low gradient near 0.\n",
    "if False:\n",
    "    do_plots(get_df(elephant_features), title=\"Elephant Features (negative case)\", heatmap=True, use_legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find features that have a particularly strong response, horizontally, vertically, and in any direction.\n",
    "if False:\n",
    "    do_plots(get_steepest(get_df(moral_factors), sortby=\"IB\"), title=\"Shallowest 5 Features\", heatmap=True)\n",
    "    do_plots(get_steepest(get_df(moral_factors), sortby=\"IH\"), title=\"Steepest 5 Features\", heatmap=True)\n",
    "    do_plots(get_steepest(get_df(moral_factors)), title=\"Top 5 Moral Features\", heatmap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just plot all features\n",
    "do_plots(get_df(moral_factors))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
